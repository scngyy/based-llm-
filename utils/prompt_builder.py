"""
Promptä¸Šä¸‹æ–‡æ„å»ºå·¥å…·ç±»
ä¸ºçŸ¥è¯†æŠ½å–æ„å»ºåŒ…å«å±‚çº§ä¸Šä¸‹æ–‡çš„Prompt
"""

import json
import logging
from typing import List, Dict, Any, Optional, Union
from pathlib import Path
import re

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PromptBuilder:
    """
    Promptæ„å»ºå™¨ - ç¬¬å››æ­¥ï¼šæ„å»ºPromptä¸Šä¸‹æ–‡ (Prompt Context Building)
    ä¸ºLLMçŸ¥è¯†æŠ½å–ä»»åŠ¡æ„å»ºåŒ…å«å®Œæ•´å±‚çº§ä¸Šä¸‹æ–‡çš„Prompt
    """
    
    def __init__(self, template_type: str = "knowledge_extraction"):
        """
        åˆå§‹åŒ–Promptæ„å»ºå™¨
        
        Args:
            template_type: Promptæ¨¡æ¿ç±»å‹
        """
        self.template_type = template_type
        
        # é¢„å®šä¹‰çš„Promptæ¨¡æ¿
        self.templates = {
            "knowledge_extraction": self._get_knowledge_extraction_template(),
            "entity_relation": self._get_entity_relation_template(),
            "concept_understanding": self._get_concept_understanding_template(),
            "qa_generation": self._get_qa_generation_template(),
            "summarization": self._get_summarization_template()
        }
        
        # å½“å‰æ¨¡æ¿
        self.current_template = self.templates.get(template_type, self.templates["knowledge_extraction"])
    
    def build_context_prompt(self, 
                           chunk: Dict[str, Any], 
                           task_description: Optional[str] = None,
                           additional_context: Optional[Dict[str, Any]] = None) -> str:
        """
        ä¸ºå•ä¸ªchunkæ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„Prompt
        
        Args:
            chunk: åŒ…å«å†…å®¹å’Œå…ƒæ•°æ®çš„chunk
            task_description: ä»»åŠ¡æè¿°ï¼ˆå¯é€‰ï¼‰
            additional_context: é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: æ„å»ºå¥½çš„Prompt
        """
        # æå–åŸºæœ¬ä¿¡æ¯
        content = chunk.get("content", "")
        metadata = chunk.get("metadata", {})
        context_path = chunk.get("context_path", "")
        
        # æ„å»ºä¸Šä¸‹æ–‡éƒ¨åˆ†
        context_section = self._build_context_section(chunk)
        
        # æ„å»ºä»»åŠ¡æè¿°éƒ¨åˆ†
        task_section = self._build_task_section(task_description, additional_context)
        
        # æ„å»ºå†…å®¹éƒ¨åˆ†
        content_section = self._build_content_section(content)
        
        # ç»„è£…å®Œæ•´çš„Prompt
        prompt = self.current_template.format(
            context=context_section,
            task_description=task_section,
            content=content_section
        )
        
        return prompt
    
    def build_batch_prompts(self, 
                          chunks: List[Dict[str, Any]], 
                          task_description: Optional[str] = None,
                          additional_context: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æ„å»ºPrompt
        
        Args:
            chunks: chunkåˆ—è¡¨
            task_description: ä»»åŠ¡æè¿°ï¼ˆå¯é€‰ï¼‰
            additional_context: é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            List[Dict[str, Any]]: åŒ…å«promptå’ŒåŸå§‹chunkä¿¡æ¯çš„åˆ—è¡¨
        """
        prompts = []
        
        for i, chunk in enumerate(chunks):
            try:
                prompt = self.build_context_prompt(chunk, task_description, additional_context)
                
                prompt_info = {
                    "prompt_id": f"prompt_{i+1:04d}",
                    "chunk_id": chunk.get("chunk_id", f"chunk_{i+1:04d}"),
                    "prompt": prompt,
                    "prompt_length": len(prompt),
                    "token_estimate": self._estimate_tokens(prompt),
                    "original_chunk": chunk,
                    "metadata": {
                        "context_path": chunk.get("context_path", ""),
                        "content_length": chunk.get("content_length", 0),
                        "hierarchy_level": chunk.get("context_level", 0)
                    }
                }
                
                prompts.append(prompt_info)
                
            except Exception as e:
                logger.error(f"æ„å»ºPromptå¤±è´¥ (chunk {i+1}): {str(e)}")
                continue
        
        logger.info(f"æˆåŠŸæ„å»º {len(prompts)} ä¸ªPrompts")
        return prompts
    
    def _build_context_section(self, chunk: Dict[str, Any]) -> str:
        """
        æ„å»ºä¸Šä¸‹æ–‡éƒ¨åˆ†
        
        Args:
            chunk: chunkä¿¡æ¯
            
        Returns:
            str: ä¸Šä¸‹æ–‡éƒ¨åˆ†æ–‡æœ¬
        """
        metadata = chunk.get("metadata", {})
        context_path = chunk.get("context_path", "")
        hierarchy_info = chunk.get("hierarchy_info", {})
        
        context_parts = []
        
        # å±‚çº§è·¯å¾„
        if context_path:
            context_parts.append(f"ğŸ“ æ–‡æ¡£å±‚çº§è·¯å¾„: {context_path}")
        
        # è¯¦ç»†å±‚çº§ä¿¡æ¯
        if hierarchy_info:
            path = hierarchy_info.get("path", [])
            level = hierarchy_info.get("level", 0)
            position = hierarchy_info.get("chunk_position", 0)
            total = hierarchy_info.get("total_chunks", 0)
            
            context_parts.append(f"ğŸ“š æ‰€å±å±‚çº§: ç¬¬{level}çº§")
            context_parts.append(f"ğŸ“– æ–‡æ¡£ä½ç½®: ç¬¬{position}å—ï¼Œå…±{total}å—")
            
            # å…·ä½“çš„æ ‡é¢˜ä¿¡æ¯
            for i, title in enumerate(path):
                context_parts.append(f"{'  ' * i}ğŸ·ï¸  {title}")
        
        # é¢å¤–çš„å…ƒæ•°æ®
        for key, value in metadata.items():
            if key.startswith("Header ") and value:
                context_parts.append(f"ğŸ“‹ {key}: {value}")
        
        return "\n".join(context_parts) if context_parts else "æ— ç‰¹å®šä¸Šä¸‹æ–‡ä¿¡æ¯"
    
    def _build_task_section(self, task_description: Optional[str], additional_context: Optional[Dict[str, Any]]) -> str:
        """
        æ„å»ºä»»åŠ¡æè¿°éƒ¨åˆ†
        
        Args:
            task_description: ä»»åŠ¡æè¿°
            additional_context: é¢å¤–ä¸Šä¸‹æ–‡
            
        Returns:
            str: ä»»åŠ¡æè¿°éƒ¨åˆ†æ–‡æœ¬
        """
        if task_description:
            return task_description
        
        # é»˜è®¤ä»»åŠ¡æè¿°
        default_tasks = {
            "knowledge_extraction": "è¯·åŸºäºä¸Šè¿°ä¸Šä¸‹æ–‡ï¼Œä»æ–‡æœ¬å†…å®¹ä¸­æå–çŸ¥è¯†ç‚¹ã€å®ä½“å’Œå…³ç³»ã€‚é‡ç‚¹å…³æ³¨ï¼š\n1. æ ¸å¿ƒæ¦‚å¿µå®šä¹‰\n2. å®ä½“é—´çš„å±‚æ¬¡å…³ç³»\n3. å±æ€§å’Œç‰¹å¾\n4. è¿‡ç¨‹å’Œæ–¹æ³•\nè¯·ä»¥ç»“æ„åŒ–çš„æ ¼å¼è¾“å‡ºæå–ç»“æœã€‚",
            "entity_relation": "è¯·ä»æ–‡æœ¬ä¸­è¯†åˆ«å®ä½“å’Œå®ƒä»¬ä¹‹é—´çš„å…³ç³»ï¼ŒåŒ…æ‹¬ï¼š\n1. å®ä½“ç±»å‹ï¼ˆæ¦‚å¿µã€äººç‰©ã€åœ°ç‚¹ã€æ—¶é—´ç­‰ï¼‰\n2. å®ä½“å±æ€§\n3. å®ä½“é—´çš„å…³ç³»ï¼ˆå±äºã€åŒ…å«ã€ä¾èµ–ã€å› æœç­‰ï¼‰\nè¯·ä»¥ä¸‰å…ƒç»„å½¢å¼è¾“å‡ºï¼š(ä¸»ä½“, å…³ç³», å®¢ä½“)ã€‚",
            "concept_understanding": "è¯·æ·±å…¥ç†è§£æ–‡æœ¬ä¸­çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå¹¶è§£é‡Šï¼š\n1. æ¦‚å¿µçš„å®šä¹‰å’Œå†…æ¶µ\n2. æ¦‚å¿µçš„å¤–å»¶å’Œå®ä¾‹\n3. ä¸å…¶ä»–æ¦‚å¿µçš„å…³ç³»\n4. åœ¨æ•´ä¸ªçŸ¥è¯†ä½“ç³»ä¸­çš„ä½ç½®",
            "qa_generation": "åŸºäºæ–‡æœ¬å†…å®¹å’Œä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆé«˜è´¨é‡çš„é—®é¢˜å’Œç­”æ¡ˆå¯¹ï¼š\n1. äº‹å®æ€§é—®é¢˜\n2. ç†è§£æ€§é—®é¢˜\n3. åº”ç”¨æ€§é—®é¢˜\n4. åˆ†ææ€§é—®é¢˜\nè¯·ç¡®ä¿ç­”æ¡ˆèƒ½åœ¨æ–‡æœ¬ä¸­æ‰¾åˆ°ä¾æ®ã€‚",
            "summarization": "è¯·ä¸ºè¿™æ®µæ–‡æœ¬ç”Ÿæˆä¸€ä¸ªç®€æ´å‡†ç¡®çš„æ‘˜è¦ï¼Œçªå‡ºï¼š\n1. ä¸»è¦è§‚ç‚¹\n2. å…³é”®ä¿¡æ¯\n3. ä¸ä¸Šä¸‹æ–‡çš„å…³è”\n4. é‡è¦ç»†èŠ‚"
        }
        
        task = default_tasks.get(self.template_type, default_tasks["knowledge_extraction"])
        
        # æ·»åŠ é¢å¤–ä¸Šä¸‹æ–‡
        if additional_context:
            extra_info = "\n\né¢å¤–ä¿¡æ¯:\n"
            for key, value in additional_context.items():
                extra_info += f"- {key}: {value}\n"
            task += extra_info
        
        return task
    
    def _build_content_section(self, content: str) -> str:
        """
        æ„å»ºå†…å®¹éƒ¨åˆ†
        
        Args:
            content: åŸå§‹å†…å®¹
            
        Returns:
            str: æ ¼å¼åŒ–çš„å†…å®¹éƒ¨åˆ†
        """
        if not content:
            return "æ— å†…å®¹"
        
        # ç®€å•çš„å†…å®¹æ ¼å¼åŒ–
        formatted_content = content.strip()
        
        # å¦‚æœå†…å®¹å¤ªé•¿ï¼Œè¿›è¡Œæˆªæ–­æç¤º
        if len(formatted_content) > 8000:
            formatted_content = formatted_content[:8000] + "\n\n[æ³¨æ„ï¼šå†…å®¹å·²æˆªæ–­ï¼Œå®Œæ•´å†…å®¹è¯·å‚è€ƒåŸå§‹æ–‡æ¡£]"
        
        return formatted_content
    
    def _get_knowledge_extraction_template(self) -> str:
        """çŸ¥è¯†æŠ½å–æ¨¡æ¿"""
        return """# çŸ¥è¯†æŠ½å–ä»»åŠ¡

## ğŸ“‹ ä¸Šä¸‹æ–‡ä¿¡æ¯
{context}

## ğŸ¯ ä»»åŠ¡æè¿°
{task_description}

## ğŸ“„ æ–‡æœ¬å†…å®¹
```
{content}
```

## ğŸ’¬ è¾“å‡ºè¦æ±‚
è¯·åŸºäºä»¥ä¸Šä¿¡æ¯è¿›è¡ŒçŸ¥è¯†æŠ½å–ï¼Œè¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
1. ç»“æ„æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜
2. åŒ…å«å®ä½“ã€å…³ç³»ã€å±æ€§
3. æ ‡æ³¨ä¿¡æ¯æ¥æºå’Œç½®ä¿¡åº¦
4. ä¿æŒJSONæ ¼å¼ä¾¿äºåç»­å¤„ç†

è¯·å¼€å§‹åˆ†æï¼š
"""
    
    def _get_entity_relation_template(self) -> str:
        """å®ä½“å…³ç³»æŠ½å–æ¨¡æ¿"""
        return """# å®ä½“å…³ç³»æŠ½å–ä»»åŠ¡

## ğŸ“‹ ä¸Šä¸‹æ–‡ä¿¡æ¯
{context}

## ğŸ¯ ä»»åŠ¡æè¿°
{task_description}

## ğŸ“„ æ–‡æœ¬å†…å®¹
```
{content}
```

## ğŸ’¬ è¾“å‡ºè¦æ±‚
è¯·ä»¥ä»¥ä¸‹æ ¼å¼è¾“å‡ºå®ä½“å…³ç³»ï¼š
```json
{
  "entities": [
    {"id": "E1", "type": "æ¦‚å¿µ", "name": "å®ä½“åç§°", "attributes": {...}},
    ...
  ],
  "relations": [
    {"subject": "E1", "predicate": "å…³ç³»ç±»å‹", "object": "E2", "confidence": 0.9},
    ...
  ]
}
```

è¯·å¼€å§‹åˆ†æï¼š
"""
    
    def _get_concept_understanding_template(self) -> str:
        """æ¦‚å¿µç†è§£æ¨¡æ¿"""
        return """# æ¦‚å¿µç†è§£ä»»åŠ¡

## ğŸ“‹ ä¸Šä¸‹æ–‡ä¿¡æ¯
{context}

## ğŸ¯ ä»»åŠ¡æè¿°
{task_description}

## ğŸ“„ æ–‡æœ¬å†…å®¹
```
{content}
```

## ğŸ’¬ è¾“å‡ºè¦æ±‚
è¯·è¯¦ç»†è§£é‡Šæ¦‚å¿µç†è§£ç»“æœï¼š
1. æ ¸å¿ƒæ¦‚å¿µå®šä¹‰
2. æ¦‚å¿µç‰¹å¾å’Œå±æ€§
3. ä¸å…¶ä»–æ¦‚å¿µçš„å…³ç³»
4. å®é™…åº”ç”¨åœºæ™¯

è¯·å¼€å§‹åˆ†æï¼š
"""
    
    def _get_qa_generation_template(self) -> str:
        """é—®ç­”ç”Ÿæˆæ¨¡æ¿"""
        return """# é—®ç­”ç”Ÿæˆä»»åŠ¡

## ğŸ“‹ ä¸Šä¸‹æ–‡ä¿¡æ¯
{context}

## ğŸ¯ ä»»åŠ¡æè¿°
{task_description}

## ğŸ“„ æ–‡æœ¬å†…å®¹
```
{content}
```

## ğŸ’¬ è¾“å‡ºè¦æ±‚
è¯·ç”Ÿæˆä»¥ä¸‹æ ¼å¼çš„é—®ç­”å¯¹ï¼š
```json
{
  "qa_pairs": [
    {
      "question": "é—®é¢˜å†…å®¹",
      "answer": "ç­”æ¡ˆå†…å®¹",
      "type": "äº‹å®æ€§/ç†è§£æ€§/åº”ç”¨æ€§/åˆ†ææ€§",
      "difficulty": "ç®€å•/ä¸­ç­‰/å›°éš¾"
    }
  ]
}
```

è¯·å¼€å§‹ç”Ÿæˆï¼š
"""
    
    def _get_summarization_template(self) -> str:
        """æ‘˜è¦ç”Ÿæˆæ¨¡æ¿"""
        return """# æ–‡æœ¬æ‘˜è¦ä»»åŠ¡

## ğŸ“‹ ä¸Šä¸‹æ–‡ä¿¡æ¯
{context}

## ğŸ¯ ä»»åŠ¡æè¿°
{task_description}

## ğŸ“„ æ–‡æœ¬å†…å®¹
```
{content}
```

## ğŸ’¬ è¾“å‡ºè¦æ±‚
è¯·ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦ï¼š
1. ä¸»è¦è§‚ç‚¹æ€»ç»“
2. å…³é”®ä¿¡æ¯æå–
3. ä¸ä¸Šä¸‹æ–‡çš„å…³è”
4. é‡è¦ç»“è®º

è¯·å¼€å§‹æ‘˜è¦ï¼š
"""
    
    def set_template_type(self, template_type: str):
        """
        è®¾ç½®æ¨¡æ¿ç±»å‹
        
        Args:
            template_type: æ¨¡æ¿ç±»å‹
        """
        if template_type in self.templates:
            self.template_type = template_type
            self.current_template = self.templates[template_type]
            logger.info(f"å·²åˆ‡æ¢åˆ°æ¨¡æ¿ç±»å‹: {template_type}")
        else:
            logger.error(f"æœªçŸ¥çš„æ¨¡æ¿ç±»å‹: {template_type}")
    
    def save_prompts(self, prompts: List[Dict[str, Any]], output_path: str):
        """
        ä¿å­˜promptsåˆ°æ–‡ä»¶
        
        Args:
            prompts: promptåˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        save_data = {
            "metadata": {
                "total_prompts": len(prompts),
                "template_type": self.template_type,
                "created_at": str(Path().absolute()),
                "total_tokens": sum(p["token_estimate"] for p in prompts)
            },
            "prompts": prompts
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Promptså·²ä¿å­˜åˆ°: {output_path}")
    
    def _estimate_tokens(self, text: str) -> int:
        """
        ä¼°ç®—tokenæ•°é‡
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            
        Returns:
            int: ä¼°ç®—çš„tokenæ•°é‡
        """
        # ç®€å•çš„tokenä¼°ç®—
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        english_words = len(re.findall(r'\b[a-zA-Z]+\b', text))
        return chinese_chars + int(english_words * 0.75)
    
    def get_prompt_statistics(self, prompts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        è·å–promptç»Ÿè®¡ä¿¡æ¯
        
        Args:
            prompts: promptåˆ—è¡¨
            
        Returns:
            Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯
        """
        if not prompts:
            return {"error": "æ²¡æœ‰å¯åˆ†æçš„prompts"}
        
        prompt_lengths = [p["prompt_length"] for p in prompts]
        token_estimates = [p["token_estimate"] for p in prompts]
        
        return {
            "total_prompts": len(prompts),
            "length_stats": {
                "min_length": min(prompt_lengths),
                "max_length": max(prompt_lengths),
                "avg_length": round(sum(prompt_lengths) / len(prompt_lengths), 2),
                "total_length": sum(prompt_lengths)
            },
            "token_stats": {
                "min_tokens": min(token_estimates),
                "max_tokens": max(token_estimates),
                "avg_tokens": round(sum(token_estimates) / len(token_estimates), 2),
                "total_tokens": sum(token_estimates)
            },
            "context_coverage": self._analyze_context_coverage(prompts)
        }
    
    def _analyze_context_coverage(self, prompts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆ†æä¸Šä¸‹æ–‡è¦†ç›–æƒ…å†µ
        
        Args:
            prompts: promptåˆ—è¡¨
            
        Returns:
            Dict[str, Any]: ä¸Šä¸‹æ–‡è¦†ç›–åˆ†æ
        """
        hierarchy_levels = [p["metadata"]["hierarchy_level"] for p in prompts]
        
        return {
            "level_distribution": {
                f"level_{level}": hierarchy_levels.count(level) 
                for level in set(hierarchy_levels)
            },
            "with_context_path": sum(1 for p in prompts if p["metadata"]["context_path"]),
            "avg_hierarchy_level": round(sum(hierarchy_levels) / len(hierarchy_levels), 2)
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºPromptæ„å»ºå™¨
    builder = PromptBuilder(template_type="knowledge_extraction")
    
    # ç¤ºä¾‹ç”¨æ³•
    try:
        # ç¤ºä¾‹chunk
        example_chunk = {
            "chunk_id": "chunk_0001",
            "content": "ç¥ç»ç½‘ç»œæ˜¯ä¸€ç§æ¨¡ä»¿äººè„‘ç»“æ„çš„è®¡ç®—æ¨¡å‹...",
            "metadata": {
                "Header 1": "ç¬¬ä¸€ç«  æ·±åº¦å­¦ä¹ åŸºç¡€",
                "Header 2": "1.1 ç¥ç»ç½‘ç»œæ¦‚å¿µ"
            },
            "context_path": "ç¬¬ä¸€ç«  æ·±åº¦å­¦ä¹ åŸºç¡€ > 1.1 ç¥ç»ç½‘ç»œæ¦‚å¿µ",
            "context_level": 2
        }
        
        # æ„å»ºprompt
        # prompt = builder.build_context_prompt(example_chunk)
        # print("æ„å»ºçš„Prompt:")
        # print(prompt)
        
        pass
    except Exception as e:
        logger.error(f"ç¤ºä¾‹è¿è¡Œå¤±è´¥: {str(e)}")